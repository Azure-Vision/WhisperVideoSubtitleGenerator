import streamlit as st
import tempfile
import os
import re
import io
from datetime import timedelta
from typing import List, Tuple
from openai import OpenAI
import ffmpeg
import imageio_ffmpeg
try:
    from moviepy.editor import VideoFileClip
    HAS_MOVIEPY = True
except ImportError:
    HAS_MOVIEPY = False

def format_timestamp(seconds: float) -> str:
    """å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ ¼å¼çš„æ—¶é—´æˆ³"""
    td = timedelta(seconds=seconds)
    hours = int(td.total_seconds() // 3600)
    minutes = int((td.total_seconds() % 3600) // 60)
    seconds = td.total_seconds() % 60
    return f"{hours:02d}:{minutes:02d}:{seconds:06.3f}".replace(".", ",")

def split_text_at_punctuation(text: str) -> List[str]:
    """åœ¨å¥å·å’Œæ„Ÿå¹å·åé¢åˆ†å‰²æ–‡æœ¬"""
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åœ¨ ". " å’Œ "! " å¤„åˆ†å‰²
    segments = re.split(r'([.!] )', text)
    
    result = []
    current_segment = ""
    
    for i, segment in enumerate(segments):
        if i % 2 == 0:  # å®é™…æ–‡æœ¬
            current_segment += segment
        else:  # æ ‡ç‚¹ç¬¦å·
            current_segment += segment.rstrip()  # ç§»é™¤æœ«å°¾ç©ºæ ¼
            if current_segment.strip():
                result.append(current_segment.strip())
            current_segment = ""
    
    # æ·»åŠ æœ€åä¸€ä¸ªæ®µè½ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    if current_segment.strip():
        result.append(current_segment.strip())
    
    return result

def split_text_by_length(text: str, max_length: int = 26) -> List[str]:
    """æŒ‰é•¿åº¦åˆ†å‰²æ–‡æœ¬ï¼Œç¡®ä¿å•è¯ä¸è¢«æˆªæ–­"""
    words = text.split()
    segments = []
    current_segment = ""
    
    for word in words:
        # æ£€æŸ¥æ·»åŠ æ–°å•è¯æ˜¯å¦ä¼šè¶…è¿‡é•¿åº¦é™åˆ¶
        test_segment = current_segment + (" " if current_segment else "") + word
        
        if len(test_segment) <= max_length:
            current_segment = test_segment
        else:
            # å¦‚æœå½“å‰æ®µè½ä¸ä¸ºç©ºï¼Œä¿å­˜å®ƒ
            if current_segment:
                segments.append(current_segment)
                current_segment = word
            else:
                # å¦‚æœå•ä¸ªå•è¯å°±è¶…è¿‡äº†é™åˆ¶ï¼Œå¼ºåˆ¶æ·»åŠ 
                segments.append(word)
                current_segment = ""
    
    # æ·»åŠ æœ€åä¸€ä¸ªæ®µè½
    if current_segment:
        segments.append(current_segment)
    
    return segments

def process_transcript_segments(segments, max_chars: int = 26) -> List[dict]:
    """å¤„ç†è½¬å½•æ®µè½ï¼ŒæŒ‰ç…§æŒ‡å®šè§„åˆ™åˆ†å‰²"""
    processed_segments = []
    
    for segment in segments:
        text = segment.text.strip()
        start_time = segment.start
        end_time = segment.end
        duration = end_time - start_time
        
        # é¦–å…ˆåœ¨æ ‡ç‚¹ç¬¦å·å¤„åˆ†å‰²
        punctuation_splits = split_text_at_punctuation(text)
        
        for i, punct_segment in enumerate(punctuation_splits):
            # ç„¶åæŒ‰é•¿åº¦åˆ†å‰²æ¯ä¸ªæ ‡ç‚¹ç¬¦å·æ®µè½
            length_splits = split_text_by_length(punct_segment, max_chars)
            
            # ä¸ºæ¯ä¸ªåˆ†å‰²çš„æ®µè½è®¡ç®—æ—¶é—´
            total_splits = len(length_splits)
            segment_duration = duration / len(punctuation_splits)
            
            for j, split_text in enumerate(length_splits):
                # è®¡ç®—æ­¤å­æ®µè½çš„å¼€å§‹å’Œç»“æŸæ—¶é—´
                subsegment_duration = segment_duration / total_splits
                subsegment_start = start_time + (i * segment_duration) + (j * subsegment_duration)
                subsegment_end = subsegment_start + subsegment_duration
                
                processed_segments.append({
                    'text': split_text,
                    'start': subsegment_start,
                    'end': subsegment_end
                })
    
    return processed_segments

def generate_raw_srt(transcript) -> str:
    """ç”ŸæˆåŸå§‹SRTï¼Œæ¯ä¸ªå•è¯ä¸€ä¸ªå­—å¹•æ®µï¼Œä½¿ç”¨ç²¾ç¡®çš„å•è¯çº§æ—¶é—´æˆ³"""
    srt_content = []
    segment_number = 1
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å•è¯çº§æ—¶é—´æˆ³
    if hasattr(transcript, 'words') and transcript.words and len(transcript.words) > 0:
        # ä½¿ç”¨ç²¾ç¡®çš„å•è¯çº§æ—¶é—´æˆ³
        for word_info in transcript.words:
            srt_content.append(f"{segment_number}")
            srt_content.append(f"{format_timestamp(word_info.start)} --> {format_timestamp(word_info.end)}")
            srt_content.append(word_info.word)
            srt_content.append("")
            segment_number += 1
    else:
        # å›é€€åˆ°æ®µè½çº§å¤„ç†ï¼ˆå¦‚æœæ²¡æœ‰å•è¯çº§æ—¶é—´æˆ³ï¼‰
        segments = getattr(transcript, 'segments', [])
        if segments:
            for segment in segments:
                words = segment.text.split()
                if not words:
                    continue
                    
                duration = segment.end - segment.start
                word_duration = duration / len(words)
                
                for i, word in enumerate(words):
                    word_start = segment.start + (i * word_duration)
                    word_end = word_start + word_duration
                    
                    srt_content.append(f"{segment_number}")
                    srt_content.append(f"{format_timestamp(word_start)} --> {format_timestamp(word_end)}")
                    srt_content.append(word)
                    srt_content.append("")
                    
                    segment_number += 1
    
    return "\n".join(srt_content)

def generate_srt(segments) -> str:
    """ç”Ÿæˆæ ‡å‡†SRTå­—å¹•æ–‡ä»¶"""
    srt_content = []
    
    for i, segment in enumerate(segments, 1):
        srt_content.append(f"{i}")
        
        # å…¼å®¹å­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ ¼å¼
        if hasattr(segment, 'start'):
            # å¯¹è±¡æ ¼å¼
            start_time = segment.start
            end_time = segment.end
            text = segment.text
        else:
            # å­—å…¸æ ¼å¼
            start_time = segment['start']
            end_time = segment['end']
            text = segment['text']
        
        srt_content.append(f"{format_timestamp(start_time)} --> {format_timestamp(end_time)}")
        srt_content.append(text)
        srt_content.append("")
    
    return "\n".join(srt_content)

def extract_audio_from_video(video_file) -> str:
    """ä»è§†é¢‘æ–‡ä»¶æå–éŸ³é¢‘"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as audio_file:
        audio_path = audio_file.name
    
    with tempfile.NamedTemporaryFile(delete=False) as video_temp:
        video_temp.write(video_file.read())
        video_temp_path = video_temp.name
    
    try:
        # è·å–ffmpegè·¯å¾„å¹¶ä½¿ç”¨å®ƒ
        ffmpeg_exe = imageio_ffmpeg.get_ffmpeg_exe()
        st.write(f"ğŸ”§ Using ffmpeg: {ffmpeg_exe}")
        
        # æ£€æŸ¥ffmpegæ˜¯å¦å¯æ‰§è¡Œ
        if not os.path.exists(ffmpeg_exe):
            raise FileNotFoundError(f"FFmpeg not found at: {ffmpeg_exe}")
            
        # ä½¿ç”¨ffmpegæå–éŸ³é¢‘
        stream = ffmpeg.input(video_temp_path)
        stream = ffmpeg.output(stream, audio_path, acodec='pcm_s16le', ar=16000)
        ffmpeg.run(stream, cmd=ffmpeg_exe, quiet=True, overwrite_output=True)
        
        os.unlink(video_temp_path)
        return audio_path
    except Exception as e:
        if os.path.exists(video_temp_path):
            os.unlink(video_temp_path)
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•ç³»ç»Ÿffmpeg
        st.warning(f"âš ï¸ imageio-ffmpeg failed: {e}")
        st.info("ğŸ”„ Trying system ffmpeg...")
        
        try:
            with tempfile.NamedTemporaryFile(delete=False) as video_temp2:
                video_file.seek(0)
                video_temp2.write(video_file.read())
                video_temp2_path = video_temp2.name
            
            stream = ffmpeg.input(video_temp2_path)
            stream = ffmpeg.output(stream, audio_path, acodec='pcm_s16le', ar=16000)
            ffmpeg.run(stream, quiet=True, overwrite_output=True)
            
            os.unlink(video_temp2_path)
            st.success("âœ… System ffmpeg worked!")
            return audio_path
            
        except Exception as e2:
            if os.path.exists(audio_path):
                os.unlink(audio_path)
            
            # æœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆï¼šMoviePy
            if HAS_MOVIEPY:
                st.info("ğŸ¬ Trying MoviePy as final option...")
                try:
                    with tempfile.NamedTemporaryFile(delete=False) as video_temp3:
                        video_file.seek(0)
                        video_temp3.write(video_file.read())
                        video_temp3_path = video_temp3.name
                    
                    # ä½¿ç”¨ MoviePy æå–éŸ³é¢‘
                    video_clip = VideoFileClip(video_temp3_path)
                    audio_clip = video_clip.audio
                    audio_clip.write_audiofile(audio_path, verbose=False, logger=None)
                    
                    # æ¸…ç†
                    audio_clip.close()
                    video_clip.close()
                    os.unlink(video_temp3_path)
                    
                    st.success("âœ… MoviePy worked!")
                    return audio_path
                    
                except Exception as e3:
                    raise Exception(f"All methods failed. imageio-ffmpeg: {e}, system ffmpeg: {e2}, moviepy: {e3}")
            else:
                raise Exception(f"Both ffmpeg methods failed. imageio-ffmpeg: {e}, system ffmpeg: {e2}")
        
        raise e

def main():
    st.set_page_config(
        page_title="è§†é¢‘å­—å¹•ç”Ÿæˆå™¨",
        page_icon="ğŸ¬",
        layout="wide"
    )
    
    st.title("ğŸ¬ è§†é¢‘å­—å¹•ç”Ÿæˆå™¨")
    st.write("ä½¿ç”¨ OpenAI Whisper ä¸ºæ‚¨çš„è§†é¢‘ç”Ÿæˆå­—å¹•")
    
    # ä»ç¯å¢ƒå˜é‡è·å–API Key
    env_api_key = os.getenv('OPENAI_API_KEY')
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("é…ç½®")
        
        if env_api_key:
            st.success("âœ… å·²ä»ç¯å¢ƒå˜é‡è·å– API Key")
            api_key = env_api_key
            # æ˜¾ç¤ºéƒ¨åˆ†API Keyç”¨äºç¡®è®¤
            masked_key = env_api_key[:8] + "..." + env_api_key[-4:] if len(env_api_key) > 12 else "***"
            st.info(f"API Key: {masked_key}")
        else:
            api_key = st.text_input(
                "OpenAI API Key",
                type="password",
                help="è¯·è¾“å…¥æ‚¨çš„ OpenAI API Keyï¼ˆæˆ–è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡ï¼‰"
            )
        
        model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["whisper-1"],
            help="é€‰æ‹©è¦ä½¿ç”¨çš„ Whisper æ¨¡å‹"
        )
        
        max_chars = st.slider(
            "æ¯æ®µå­—å¹•æœ€å¤§å­—ç¬¦æ•°",
            min_value=20,
            max_value=100,
            value=26,
            help="æ¯ä¸ªå­—å¹•æ®µçš„æœ€å¤§å­—ç¬¦æ•°é™åˆ¶"
        )
    
    # ä¸»ç•Œé¢
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ä¸Šä¼ è§†é¢‘æ–‡ä»¶")
        uploaded_file = st.file_uploader(
            "é€‰æ‹©è§†é¢‘æ–‡ä»¶",
            type=['mp4', 'avi', 'mov', 'mkv', 'wmv', 'flv'],
            help="æ”¯æŒå¸¸è§çš„è§†é¢‘æ ¼å¼"
        )
        
        if uploaded_file and api_key:
            if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆå­—å¹•", type="primary"):
                try:
                    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                    client = OpenAI(api_key=api_key)
                    
                    with st.spinner("æ­£åœ¨æå–éŸ³é¢‘..."):
                        audio_path = extract_audio_from_video(uploaded_file)
                        # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¤§å°
                        audio_size = os.path.getsize(audio_path)
                        st.write(f"ğŸµ éŸ³é¢‘æ–‡ä»¶å¤§å°: {audio_size / 1024 / 1024:.2f} MB")
                    
                    with st.spinner("æ­£åœ¨ç”Ÿæˆå­—å¹•..."):
                        with open(audio_path, 'rb') as audio_file:
                            transcript = client.audio.transcriptions.create(
                                file=audio_file,
                                model="whisper-1",
                                response_format="verbose_json",
                                timestamp_granularities=["word", "segment"]
                            )
                    
                    # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                    os.unlink(audio_path)
                    
                    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                    st.write("ğŸ” **è°ƒè¯•ä¿¡æ¯ï¼š**")
                    st.write(f"- transcript ç±»å‹: {type(transcript)}")
                    st.write(f"- æ˜¯å¦æœ‰ words å±æ€§: {hasattr(transcript, 'words')}")
                    st.write(f"- æ˜¯å¦æœ‰ segments å±æ€§: {hasattr(transcript, 'segments')}")
                    
                    if hasattr(transcript, 'words'):
                        words_count = len(transcript.words) if transcript.words else 0
                        st.write(f"- words æ•°é‡: {words_count}")
                        if words_count > 0:
                            st.write(f"- ç¬¬ä¸€ä¸ª word: {transcript.words[0]}")
                    
                    if hasattr(transcript, 'segments'):
                        segments_count = len(transcript.segments) if transcript.segments else 0
                        st.write(f"- segments æ•°é‡: {segments_count}")
                        if segments_count > 0:
                            st.write(f"- ç¬¬ä¸€ä¸ª segment: {transcript.segments[0]}")
                    
                    # æ˜¾ç¤ºå®Œæ•´çš„ transcript å¯¹è±¡ï¼ˆå‰100ä¸ªå­—ç¬¦ï¼‰
                    st.write(f"- transcript å†…å®¹é¢„è§ˆ: {str(transcript)[:500]}...")
                    
                    with st.spinner("æ­£åœ¨å¤„ç†å­—å¹•æ®µè½..."):
                        # å¤„ç†å­—å¹•æ®µè½ï¼Œæ·»åŠ å®‰å…¨æ£€æŸ¥
                        segments = getattr(transcript, 'segments', [])
                        
                        if segments and len(segments) > 0:
                            st.write("âœ… ä½¿ç”¨APIè¿”å›çš„segmentsæ•°æ®")
                            
                            # åˆ›å»ºå•è¯åˆ°æ—¶é—´æˆ³çš„æ˜ å°„
                            words_timing = {}
                            if hasattr(transcript, 'words') and transcript.words:
                                for word_info in transcript.words:
                                    # ä½¿ç”¨å•è¯æ–‡æœ¬ä½œä¸ºé”®ï¼Œå­˜å‚¨æ—¶é—´ä¿¡æ¯
                                    word_key = word_info.word.strip()
                                    if word_key not in words_timing:
                                        words_timing[word_key] = []
                                    words_timing[word_key].append({
                                        'start': word_info.start,
                                        'end': word_info.end,
                                        'used': False
                                    })
                            
                            # å¤„ç†æ¯ä¸ªsegmentï¼ŒæŒ‰å­—ç¬¦æ•°å’Œæ ‡ç‚¹åˆ†æ®µ
                            class TempSegment:
                                def __init__(self, text, start, end):
                                    self.text = text
                                    self.start = start
                                    self.end = end
                            
                            processed_segments_list = []
                            
                            for segment in segments:
                                segment_text = segment.text.strip()
                                segment_words = segment_text.split()
                                
                                # ä¸ºsegmentä¸­çš„æ¯ä¸ªå•è¯æ‰¾åˆ°å¯¹åº”çš„æ—¶é—´æˆ³
                                word_timings = []
                                for word in segment_words:
                                    clean_word = word.strip('.,!?;:"()[]')  # ç§»é™¤æ ‡ç‚¹ç¬¦å·è¿›è¡ŒåŒ¹é…
                                    
                                    # æŸ¥æ‰¾å¯¹åº”çš„æ—¶é—´æˆ³
                                    found_timing = None
                                    if clean_word in words_timing:
                                        for timing_info in words_timing[clean_word]:
                                            if not timing_info['used']:
                                                found_timing = timing_info
                                                timing_info['used'] = True
                                                break
                                    
                                    if found_timing:
                                        word_timings.append({
                                            'word': word,
                                            'start': found_timing['start'],
                                            'end': found_timing['end']
                                        })
                                    else:
                                        # å¦‚æœæ‰¾ä¸åˆ°ç²¾ç¡®åŒ¹é…ï¼Œä½¿ç”¨segmentçš„æ—¶é—´è¿›è¡Œä¼°ç®—
                                        word_index = segment_words.index(word)
                                        total_words = len(segment_words)
                                        duration = segment.end - segment.start
                                        word_duration = duration / total_words
                                        estimated_start = segment.start + (word_index * word_duration)
                                        estimated_end = estimated_start + word_duration
                                        
                                        word_timings.append({
                                            'word': word,
                                            'start': estimated_start,
                                            'end': estimated_end
                                        })
                                
                                # é¦–å…ˆæŒ‰å¥å­ç»“æŸæ ‡ç‚¹ç¬¦å·åˆ†æ®µï¼Œç„¶åæŒ‰å­—ç¬¦æ•°åˆ†æ®µ
                                current_words = []
                                current_timings = []
                                
                                for i, (word, timing) in enumerate(zip(segment_words, word_timings)):
                                    current_words.append(word)
                                    current_timings.append(timing)
                                    
                                    # åˆ†æ®µæ¡ä»¶ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
                                    should_split = False
                                    
                                    # 1. ä¼˜å…ˆçº§æœ€é«˜ï¼šå¥å­ç»“æŸæ ‡ç‚¹ç¬¦å· + ä¸‹ä¸€ä¸ªå•è¯å¤§å†™å¼€å¤´ï¼ˆçœŸæ­£çš„æ–°å¥å­ï¼‰
                                    # æ’é™¤å¸¸è§ç¼©å†™è¯
                                    common_abbreviations = ['Dr.', 'Mr.', 'Mrs.', 'Ms.', 'Prof.', 'St.', 'Ave.', 'etc.', 'vs.', 'Inc.', 'Ltd.', 'Co.']
                                    if (i < len(segment_words) - 1 and 
                                        any(word.endswith(punct) for punct in ['.', '!', '?']) and
                                        segment_words[i + 1][0].isupper() and
                                        word not in common_abbreviations):
                                        should_split = True
                                    
                                    # 2. æœ€åä¸€ä¸ªå•è¯
                                    elif i == len(segment_words) - 1:
                                        should_split = True
                                    
                                    # 3. è¶…è¿‡26ä¸ªå­—ç¬¦ä¸”æœ‰å¤šä¸ªå•è¯æ—¶ï¼Œåœ¨ä¸Šä¸€ä¸ªå•è¯å¤„åˆ†æ®µ
                                    elif len(' '.join(current_words)) > 26 and len(current_words) > 1:
                                        # å›é€€ä¸€ä¸ªå•è¯ï¼Œåœ¨å‰é¢åˆ†æ®µ
                                        current_words.pop()
                                        current_timings.pop()
                                        
                                        if current_timings:  # ç¡®ä¿æœ‰å†…å®¹å¯ä»¥åˆ†æ®µ
                                            current_text = ' '.join(current_words)
                                            start_time = current_timings[0]['start']
                                            end_time = current_timings[-1]['end']
                                            
                                            processed_segments_list.append(TempSegment(current_text, start_time, end_time))
                                        
                                        # é‡æ–°å¼€å§‹ï¼ŒåŒ…å«å½“å‰å•è¯
                                        current_words = [word]
                                        current_timings = [timing]
                                        should_split = False
                                    
                                    if should_split and current_timings:
                                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªå•è¯çš„ç²¾ç¡®æ—¶é—´æˆ³
                                        current_text = ' '.join(current_words)
                                        start_time = current_timings[0]['start']
                                        end_time = current_timings[-1]['end']
                                        
                                        processed_segments_list.append(TempSegment(current_text, start_time, end_time))
                                        current_words = []
                                        current_timings = []
                            
                            processed_segments = processed_segments_list
                            
                        elif hasattr(transcript, 'words') and transcript.words:
                            st.write("âš ï¸ segmentsä¸ºç©ºï¼Œä½¿ç”¨wordsé‡æ–°æ„å»º")
                            # åŸæœ‰çš„wordsé‡æ„é€»è¾‘ä¿æŒä¸å˜
                            # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„segmentå¯¹è±¡
                            class TempSegment:
                                def __init__(self, text, start, end):
                                    self.text = text
                                    self.start = start
                                    self.end = end
                            
                            # æ™ºèƒ½åˆ†æ®µï¼šåŸºäºå¥å­ç»“æ„å’Œæ ‡ç‚¹ç¬¦å·
                            segments = []
                            current_words = []
                            segment_start = None
                            
                            def is_sentence_start(word_text):
                                """åˆ¤æ–­æ˜¯å¦æ˜¯å¥å­å¼€å§‹ï¼ˆé¦–å­—æ¯å¤§å†™ä¸”ä¸æ˜¯å¸¸è§ç¼©å†™ï¼‰"""
                                if not word_text:
                                    return False
                                # æ£€æŸ¥é¦–å­—æ¯æ˜¯å¦å¤§å†™
                                return word_text[0].isupper() and len(word_text) > 1
                            
                            def has_sentence_ending(word_text):
                                """åˆ¤æ–­å•è¯æ˜¯å¦åŒ…å«å¥å­ç»“æŸæ ‡ç‚¹"""
                                return any(punct in word_text for punct in ['.', '!', '?'])
                            

                            
                            for i, word in enumerate(transcript.words):
                                if segment_start is None:
                                    segment_start = word.start
                                
                                current_words.append(word.word)
                                
                                # åˆ†æ®µæ¡ä»¶ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
                                should_segment = False
                                
                                # 1. æœ€åä¸€ä¸ªå•è¯
                                if i == len(transcript.words) - 1:
                                    should_segment = True
                                
                                # 2. å½“å‰å•è¯æœ‰å¥å­ç»“æŸæ ‡ç‚¹
                                elif has_sentence_ending(word.word):
                                    should_segment = True
                                
                                # 3. ä¸‹ä¸€ä¸ªå•è¯æ˜¯æ–°å¥å­å¼€å§‹ï¼ˆå¤§å†™å­—æ¯ï¼‰ï¼Œä¸”å½“å‰æ®µè½æœ‰è‡³å°‘2ä¸ªå•è¯
                                elif i + 1 < len(transcript.words) and len(current_words) >= 2:
                                    next_word = transcript.words[i + 1]
                                    if is_sentence_start(next_word.word):
                                        should_segment = True
                                
                                # 4. é•¿æ—¶é—´åœé¡¿ï¼ˆè¶…è¿‡1.2ç§’ï¼‰
                                elif i + 1 < len(transcript.words):
                                    next_word = transcript.words[i + 1]
                                    if next_word.start - word.end > 1.2:
                                        should_segment = True
                                
                                # 5. æ®µè½è¿‡é•¿ï¼ˆè¶…è¿‡12ä¸ªå•è¯ï¼‰å¼ºåˆ¶åˆ†æ®µ
                                elif len(current_words) >= 12:
                                    should_segment = True
                                
                                if should_segment:
                                    # ä¿æŒWhisperåŸå§‹æ–‡æœ¬ä¸å˜
                                    segment_text = ' '.join(current_words)
                                    segments.append(TempSegment(segment_text, segment_start, word.end))
                                    current_words = []
                                    segment_start = None
                            
                            processed_segments = segments
                        else:
                            processed_segments = []
                        
                        # ç”ŸæˆSRTæ–‡ä»¶
                        standard_srt = generate_srt(processed_segments)
                        raw_srt = generate_raw_srt(transcript)
                        
                        # æ·»åŠ SRTè°ƒè¯•ä¿¡æ¯
                        st.write("ğŸ“ **SRTç”Ÿæˆè°ƒè¯•ä¿¡æ¯ï¼š**")
                        st.write(f"- å¤„ç†åçš„æ®µè½æ•°: {len(processed_segments)}")
                        st.write(f"- æ ‡å‡†SRTé•¿åº¦: {len(standard_srt)} å­—ç¬¦")
                        st.write(f"- åŸå§‹SRTé•¿åº¦: {len(raw_srt)} å­—ç¬¦")
                        if len(standard_srt) > 0:
                            st.write(f"- æ ‡å‡†SRTé¢„è§ˆ: {standard_srt[:200]}...")
                        if len(raw_srt) > 0:
                            st.write(f"- åŸå§‹SRTé¢„è§ˆ: {raw_srt[:200]}...")
                    
                    st.success("âœ… å­—å¹•ç”Ÿæˆå®Œæˆï¼")
                    
                    # æ˜¾ç¤ºç»“æœ
                    with col2:
                        st.header("ä¸‹è½½å­—å¹•")
                        
                        # æ ‡å‡†SRTä¸‹è½½
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½æ ‡å‡†SRTå­—å¹•",
                            data=standard_srt,
                            file_name=f"{uploaded_file.name.rsplit('.', 1)[0]}.srt",
                            mime="text/plain"
                        )
                        
                        # åŸå§‹SRTä¸‹è½½
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½åŸå§‹SRTå­—å¹•ï¼ˆè°ƒè¯•ç”¨ï¼‰",
                            data=raw_srt,
                            file_name=f"{uploaded_file.name.rsplit('.', 1)[0]}_raw.srt",
                            mime="text/plain"
                        )
                        
                        st.info(f"ğŸ“Š å…±ç”Ÿæˆ {len(processed_segments)} ä¸ªå­—å¹•æ®µ")
                    
                    # é¢„è§ˆå­—å¹•
                    st.header("å­—å¹•é¢„è§ˆ")
                    
                    # é€‰æ‹©é¢„è§ˆç±»å‹
                    preview_type = st.radio(
                        "é€‰æ‹©é¢„è§ˆç±»å‹",
                        ["æ ‡å‡†å­—å¹•", "åŸå§‹å­—å¹•ï¼ˆæ¯ä¸ªå•è¯ï¼‰"],
                        horizontal=True
                    )
                    
                    if preview_type == "æ ‡å‡†å­—å¹•":
                        preview_segments = processed_segments[:10]  # åªæ˜¾ç¤ºå‰10ä¸ªæ®µè½
                        st.write("**æ ‡å‡†å­—å¹•é¢„è§ˆï¼ˆå‰10æ®µï¼‰ï¼š**")
                    else:
                        # ä¸ºåŸå§‹å­—å¹•åˆ›å»ºé¢„è§ˆæ®µè½
                        raw_segments = []
                        if hasattr(transcript, 'words') and transcript.words and len(transcript.words) > 0:
                            # ä½¿ç”¨ç²¾ç¡®çš„å•è¯çº§æ—¶é—´æˆ³ï¼ˆå‰20ä¸ªå•è¯ï¼‰
                            for word_info in transcript.words[:20]:
                                raw_segments.append({
                                    'text': word_info.word,
                                    'start': word_info.start,
                                    'end': word_info.end
                                })
                        else:
                            # å›é€€åˆ°æ®µè½çº§å¤„ç†
                            segments = getattr(transcript, 'segments', [])
                            if segments:
                                for segment in segments[:3]:  # åªå¤„ç†å‰3ä¸ªåŸå§‹æ®µè½
                                    words = segment.text.split()
                                    duration = segment.end - segment.start
                                    word_duration = duration / len(words)
                                    
                                    for i, word in enumerate(words):
                                        word_start = segment.start + (i * word_duration)
                                        word_end = word_start + word_duration
                                        raw_segments.append({
                                            'text': word,
                                            'start': word_start,
                                            'end': word_end
                                        })
                        
                        preview_segments = raw_segments
                        st.write("**åŸå§‹å­—å¹•é¢„è§ˆï¼ˆå•è¯çº§ç²¾ç¡®æ—¶é—´æˆ³ï¼‰ï¼š**")
                    
                    for i, segment in enumerate(preview_segments, 1):
                        # å…¼å®¹å­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ ¼å¼
                        if hasattr(segment, 'start'):
                            # å¯¹è±¡æ ¼å¼
                            start_time = format_timestamp(segment.start)
                            end_time = format_timestamp(segment.end)
                            text = segment.text
                        else:
                            # å­—å…¸æ ¼å¼
                            start_time = format_timestamp(segment['start'])
                            end_time = format_timestamp(segment['end'])
                            text = segment['text']
                        
                        st.write(f"**{i}.** `{start_time} --> {end_time}`")
                        st.write(f"   {text}")
                        st.write("")
                
                except Exception as e:
                    st.error(f"âŒ ç”Ÿæˆå­—å¹•æ—¶å‡ºé”™: {str(e)}")
        
        elif uploaded_file and not api_key:
            st.warning("âš ï¸ è¯·åœ¨ä¾§è¾¹æ è¾“å…¥ OpenAI API Key")
        
        # ä½¿ç”¨è¯´æ˜
        with st.expander("ğŸ“‹ ä½¿ç”¨è¯´æ˜"):
            st.write("""
            **åŠŸèƒ½ç‰¹ç‚¹ï¼š**
            - æ”¯æŒå¤šç§è§†é¢‘æ ¼å¼ï¼ˆMP4, AVI, MOV, MKV, WMV, FLVï¼‰
            - ä½¿ç”¨ OpenAI Whisper è¿›è¡Œé«˜è´¨é‡è¯­éŸ³è½¬å½•
            - æ™ºèƒ½å­—å¹•åˆ†æ®µï¼š
              - åœ¨å¥å·å’Œæ„Ÿå¹å·åè‡ªåŠ¨åˆ†æ®µ
              - æ¯æ®µæœ€å¤š26ä¸ªå­—ç¬¦ï¼ˆå¯è°ƒï¼‰
              - ä¿æŒå•è¯å®Œæ•´æ€§
            - ç”Ÿæˆä¸¤ç§SRTæ–‡ä»¶ï¼š
              - æ ‡å‡†å­—å¹•æ–‡ä»¶ï¼ˆä¼˜åŒ–åçš„æ®µè½ï¼‰
              - åŸå§‹å­—å¹•æ–‡ä»¶ï¼ˆæ¯ä¸ªå•è¯ä¸€æ®µï¼Œä½¿ç”¨ç²¾ç¡®çš„å•è¯çº§æ—¶é—´æˆ³ï¼‰
            
            **ä½¿ç”¨æ­¥éª¤ï¼š**
            1. åœ¨ä¾§è¾¹æ è¾“å…¥ OpenAI API Key
            2. ä¸Šä¼ è§†é¢‘æ–‡ä»¶
            3. ç‚¹å‡»"å¼€å§‹ç”Ÿæˆå­—å¹•"
            4. ç­‰å¾…å¤„ç†å®Œæˆ
            5. ä¸‹è½½ç”Ÿæˆçš„SRTå­—å¹•æ–‡ä»¶
            """)

if __name__ == "__main__":
    main() 